{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40bcf90-d790-4980-bd41-6862077acbb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 04_Data_Cleaning_and_EDA\n",
    "This notebook explores the Exploratory Data Analysis (EDA) of both Numerical and Categorical variables, to produce a final, clean dataset ready for AI pipeline.\n",
    "\n",
    "## Data Understanding:\n",
    "* Analyzing distribution of drugs, conditions, and ratings.\n",
    "* **Data Quality:** Identifying and removing noise (short reviews).\n",
    "* **Preprocessing:** preparing a \"Cleaned\" table for the AI pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407132c3-1fff-44cb-aae9-e21a2596c9b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c873e92-a10d-4351-aef5-04c76ff4d107",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, col, max, min, count, when, avg, stddev\n",
    "from pyspark.sql.functions import col, count, when, isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "607c9227-b270-4968-9066-c5d7faa37b4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setup Context\n",
    "catalog = \"safety_signal_catalog\"\n",
    "schema  = \"raw_data\"\n",
    "\n",
    "# Load Silver Data\n",
    "df_silver = spark.read.table(f\"{catalog}.{schema}.silver_drug_reviews\")\n",
    "\n",
    "print(f\"Loaded Silver Data. Total Records: {df_silver.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f289e73-55b0-4eb2-9fb7-551baf9654fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. NUMERICAL VARIABLE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb519bdb-b656-4084-a981-744b89a6f7ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CHECK FOR MISSING VALUES\n",
    "print(\"----- Missing Values Check -----\")\n",
    "df_silver.select([count(when(col(c).isNull(), c)).alias(c) for c in df_silver.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15fdacd8-a643-46b0-b1aa-e16ca57535c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation: Missing Values\n",
    "* There are **899 rows** where the `condition` is null.\n",
    "* To maintain medical accuracy, these conditions will not be imputed(guessed).Since the AI model predicts based on the `review` text, these missing labels do not hinder the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85a4e9c0-7ef1-4ce5-908c-b9bae124e2f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CHECK FOR DUPLICATE VALUES\n",
    "total_count = df_silver.count()\n",
    "distinct_count = df_silver.distinct().count()\n",
    "duplicate_count = total_count - distinct_count\n",
    "\n",
    "print(\"----- Duplicate Values Check -----\")\n",
    "print(f\"Total Rows:    {total_count}\")\n",
    "print(f\"Distinct Rows: {distinct_count}\")\n",
    "print(f\"Duplicates:    {duplicate_count}\")\n",
    "if duplicate_count > 0:\n",
    "    print(\"Duplicates found!\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34fd3f01-27b4-4348-92f5-0aa88ec477a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# VALIDITY & CONSISTENCY (Range Checks)\n",
    "print(\"\\n--- Validity & Range Checks ---\")\n",
    "df_silver.select(\n",
    "    min(\"rating\").alias(\"Min Rating (Should be 1)\"), \n",
    "    max(\"rating\").alias(\"Max Rating (Should be 10)\"),\n",
    "    min(\"usefulCount\").alias(\"Min Useful (Should be >=0)\"),\n",
    "    max(\"event_date\").alias(\"Latest Date\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b13dd1a-5d8a-4fdd-a222-ef3d16bc5b39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "* All ratings fall strictly between **1 and 10**, and there are no future dates.\n",
    "* The dataset is highly robust with **0 duplicates**, ensuring that the model won't memorize repeated examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0316a170-e7de-4f66-8fe9-76bea52d9b5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CHECKING TEXT LENGTH FOR NLP USAGE\n",
    "short_reviews = df_silver.filter(length(col(\"clean_review\")) < 5)\n",
    "short_count = short_reviews.count()\n",
    "\n",
    "print(f\"----- Text Length Check for NLP -----\")\n",
    "print(f\"Short/Empty Reviews (Noise): {short_count}\")\n",
    "\n",
    "if short_count > 0:\n",
    "    print(\"View Short/Empty Reviews:\")\n",
    "    display(short_reviews.select(\"rating\", \"clean_review\", \"drugName\"))\n",
    "else:\n",
    "    print(\"No short reviews found. Data is clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a205818-3e80-4eec-8f25-1a75b8de3cf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation: Noise Detection\n",
    "* There are **10 reviews** with less than 5 characters (e.g., `\"-\"`, `\"hi\"`, `\"Ok\"`).\n",
    "* As these are \"Low Information\" rows and they contain no sentiment or medical signal, these are **DROPPED** in the final cleaning step to prevent them from confusing the TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc3acdd-6e0d-4943-9412-93dc0aa738c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SUMMARY STATISTICS (Distribution)\n",
    "# Understanding the spread of the numeric data\n",
    "print(\"\\n----- Summary Statistics -----\")\n",
    "df_silver.select(\"rating\", \"usefulCount\").summary(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560690c6-21eb-4be3-abc1-c2b27310e44e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation: \n",
    "* **Statistical Skew:** The mean rating is **6.99**, indicating a \"Positivity Bias\" (patients are more likely to share success stories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d3f1990-72de-41ed-a189-a9a1f08c77f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3. CATEGORICAL VARIABLE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9299c51-36db-442d-9279-8000a0da8c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, col\n",
    "\n",
    "print(\"----- Categorical Variable Analysis -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b501e196-dbd2-466c-81dd-f12e374f1dcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cardinality (How many unique drugs/conditions?)\n",
    "# High cardinality in 'condition' suggests the data is covering many rare diseases.\n",
    "df_silver.select(\n",
    "    countDistinct(\"drugName\").alias(\"Unique Drugs\"),\n",
    "    countDistinct(\"condition\").alias(\"Unique Conditions\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c3b4651-ea66-4df8-aad9-141eb8e48c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With **3,436 unique drugs** and **884 conditions**, the data has a \"long-tail\" distribution. The model will likely perform better on common drugs than rare ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b7fde9-beaa-451c-9fdf-05847de0a851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 10 Conditions\n",
    "print(\"Top 10 Conditions by Review Count:\")\n",
    "top_conditions = df_silver.groupBy(\"condition\").count().orderBy(col(\"count\").desc())\n",
    "display(top_conditions.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45dd104c-c70f-48a0-8919-29a072579a49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "* The dataset is heavily skewed towards **Women's Health** (Birth Control: ~28,000 reviews) and **Mental Health** (Depression: ~9,000 reviews).\n",
    "* The model will likely be biased toward these therapeutic areas. It may be less effective at detecting side effects for rare conditions (e.g., Oncology) due to lack of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0698e8-39ae-484a-bab0-e54da34ddb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 10 Drugs\n",
    "print(\"Top 10 Drugs by Review Count:\")\n",
    "top_drugs = df_silver.groupBy(\"drugName\").count().orderBy(col(\"count\").desc())\n",
    "display(top_drugs.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ac76e0d-73e9-49e7-9027-4034654b26b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 4. VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b36d4ff-821f-4406-b2e2-278edcd9ca7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97acd574-9d3a-40f7-af2e-eac198432bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "volume_path = f\"/Volumes/{catalog}/{schema}/landing_zone/Visualization_Plots.png\"\n",
    "sns.set_context(\"talk\") \n",
    "sns.set_style(\"whitegrid\") \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 9))\n",
    "\n",
    "# --- PLOT 1: RATINGS DISTRIBUTION (Left) ---\n",
    "# Aggregating in Spark first\n",
    "ratings_plot = df_silver.groupBy(\"rating\").count().orderBy(\"rating\").toPandas()\n",
    "\n",
    "# Plot on the first axis (axes[0])\n",
    "sns.barplot(\n",
    "    x=\"rating\", \n",
    "    y=\"count\", \n",
    "    data=ratings_plot, \n",
    "    palette=\"viridis\", \n",
    "    hue=\"rating\", \n",
    "    legend=False,\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Distribution of Patient Ratings\", fontsize=22, fontweight='bold', pad=20)\n",
    "axes[0].set_xlabel(\"Satisfaction Score (1-10)\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Count of Reviews\", fontsize=16)\n",
    "sns.despine(left=True, ax=axes[0]) # Remove left border line for modern look\n",
    "\n",
    "# Add clean labels on top\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fontsize=12, padding=5, fmt='%.0f')\n",
    "\n",
    "\n",
    "# --- PLOT 2: TOP 10 CONDITIONS (Right) ---\n",
    "# Aggregating in Spark first\n",
    "conditions_plot = (df_silver.groupBy(\"condition\")\n",
    "                  .count()\n",
    "                  .orderBy(col(\"count\").desc())\n",
    "                  .limit(10)\n",
    "                  .toPandas())\n",
    "\n",
    "# Plot on the second axis (axes[1])\n",
    "sns.barplot(\n",
    "    x=\"count\", \n",
    "    y=\"condition\", \n",
    "    data=conditions_plot, \n",
    "    palette=\"rocket\", \n",
    "    hue=\"condition\", \n",
    "    legend=False,\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"Top 10 Conditions (Domain Bias)\", fontsize=22, fontweight='bold', pad=20)\n",
    "axes[1].set_xlabel(\"Number of Reviews\", fontsize=16)\n",
    "axes[1].set_ylabel(\"\") # Hide y-label as text explains it\n",
    "sns.despine(left=True, ax=axes[1])\n",
    "\n",
    "# Add clean labels to the right of the bars\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fontsize=12, padding=5, fmt='%.0f')\n",
    "\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(volume_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"Saved to Volume: {volume_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a856b1d7-c8e1-4413-a373-147ce5807556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "* **Ratings Distribution (Left Chart):** The data exhibits a clear **U-Shaped Distribution** (Polarity). The vast majority of reviews are either extremely negative (1/10) or extremely positive (10/10). This polarity is beneficial for a Binary Classification model as the signal between \"Safe\" and \"Adverse\" is distinct.\n",
    "* **Condition Bias (Right Chart):** The dominance of \"Birth Control\" is visually confirmed. This suggests that **Class Imbalance** is a greater challenge in this project than Label Imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdad3e1b-767f-45df-99da-d39aa1572084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Interpretation:\n",
    "* **Ratings Distribution (Left Chart):** The data exhibits a clear **U-Shaped Distribution** (Polarity). The vast majority of reviews are either extremely negative (1-2) or extremely positive (9-10).\n",
    "    * **Action:** This polarity is leveraged by **dropping the ambiguous \"Neutral\" ratings (5-6)** in the modeling stage to sharpen the decision boundary.\n",
    "* **Condition Bias (Right Chart):** The visual dominance of \"Birth Control\" confirms significant **Domain Bias**.\n",
    "    * **Action:** We will not downsample this (as it reflects real-world prevalence), but we will rely on **TF-IDF Vectorization** to penalize generic high-frequency terms associated with this dominant group, ensuring the model remains sensitive to rare signals in other conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b700bb3-e7cf-454e-88e0-e417709d1972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 5. FINAL CLEANING & SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2440211-88d5-4810-99fd-21e5c4d76d56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import length, col\n",
    "\n",
    "# 1. DROP the 10 \"Noise\" reviews (< 5 chars)\n",
    "# 2. KEEP the 899 null conditions (Scientific Integrity)\n",
    "df_cleaned = df_silver.filter(length(col(\"clean_review\")) >= 5)\n",
    "\n",
    "dropped_count = df_silver.count() - df_cleaned.count()\n",
    "print(f\"Dropped {dropped_count} noisy rows.\")\n",
    "print(f\"Final Cleaned Count: {df_cleaned.count()}\")\n",
    "\n",
    "# Save to Silver (Cleaned)\n",
    "table_name = f\"{catalog}.{schema}.silver_drug_reviews_cleaned\"\n",
    "print(f\"Saving to {table_name}...\")\n",
    "\n",
    "(df_cleaned.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(table_name)\n",
    ")\n",
    "\n",
    "print(\"Data is clean. Ready for modeling\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Data_Cleaning_and_EDA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
